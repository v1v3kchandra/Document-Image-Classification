{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKN8aG1J5w94"
   },
   "source": [
    "All the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXWTx9ZD5o49"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opPgO3Gq51Wi"
   },
   "source": [
    "This is used to establish connection to the google drive, we are storing the data on google drive and extracting the zipped folder and storing the saved back on the drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azxCv4o765Ae",
    "outputId": "5ed91f7d-ff0e-4ca9-8cba-32c7398c22cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjVAjJ9p7P38"
   },
   "source": [
    "This is used to extract zipped data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mvd3Rn6j7UY9"
   },
   "outputs": [],
   "source": [
    "import shutil  # package used to extract data\n",
    "\n",
    "shutil.unpack_archive(\"/content/drive/MyDrive/rvl-cdip.tar.gz\", \"/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Byoj79Mm7XV1"
   },
   "source": [
    "Data preprocessing of testing data and cross-validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AkqkbLB7bYf"
   },
   "outputs": [],
   "source": [
    "# Read and process the testing data labels\n",
    "test_p = open(\"/data/labels/test.txt\").readlines()\n",
    "test = []  # List to store the testing image paths\n",
    "y_test = []  # List to store corresponding testing labels\n",
    "for path in test_p:\n",
    "    pth = path.split(\"\\n\")  # split the line to get the image path and label\n",
    "    pth, l = pth[0].split(\" \")  # split the path and label\n",
    "\n",
    "    p = \"/data/images/\" + pth  # Construct the full image path\n",
    "    if (\n",
    "        p == \"/data/images/imagese/e/j/e/eje42e00/2500126531_2500126536.tif\"\n",
    "    ):  # removing the specific test image as it is corrupt\n",
    "        continue\n",
    "    test.append(p)  # add image path to the test list\n",
    "    y_test.append(int(l))  # Convert label to integer and add to y_test\n",
    "\n",
    "# Read and process the cv(cross-validation) data labels\n",
    "cv_p = open(\n",
    "    \"/data/labels/val.txt\"\n",
    ").readlines()  # split the line to get the image path and label\n",
    "cv = []  # list to store cv image paths\n",
    "y_cv = []  # list to store corresponding cv labels\n",
    "for path in cv_p:\n",
    "    pth = path.split(\"\\n\")  # split the line to get the image path and label\n",
    "    pth, l = pth[0].split(\" \")  # split the path and label\n",
    "    p = \"/data/images/\" + pth  # Construct the full image path\n",
    "\n",
    "    cv.append(p)  # Add image path to the cv list\n",
    "    y_cv.append(int(l))  # Convert label to integer and add to y_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1mAzT4-71Et"
   },
   "source": [
    "Storing the data into Dataframes of image paths and labels as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LvmZlej75bD"
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(list(zip(test, y_test)), columns=[\"paths\", \"labels\"])\n",
    "df_test.labels = df_test.labels.astype(int)\n",
    "\n",
    "df_cv = pd.DataFrame(list(zip(cv, y_cv)), columns=[\"paths\", \"labels\"])\n",
    "df_cv.labels = df_cv.labels.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnxEk58x79kO"
   },
   "source": [
    "Creating subfolders for each class and storing images for that particular class within them, used later with ImageFolder for generating DataLoader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FYpBlnZ8Pgg"
   },
   "outputs": [],
   "source": [
    "# move the images to test folders\n",
    "for i in range(0, 16):\n",
    "    if not os.path.exists(\"/dataset/test/\" + str(i)):\n",
    "        os.makedirs(\"/dataset/test/\" + str(i))\n",
    "for i in range(0, 16):\n",
    "    paths = list(df_test[df_test.labels == i].paths.values)\n",
    "    for path in paths:\n",
    "        try:\n",
    "            shutil.move(path, \"/dataset/test/\" + str(i))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# move the images to cv folders\n",
    "for i in range(0, 16):\n",
    "    if not os.path.exists(\"/dataset/cv/\" + str(i)):\n",
    "        os.makedirs(\"/dataset/cv/\" + str(i))\n",
    "for i in range(0, 16):\n",
    "    paths = list(df_cv[df_cv.labels == i].paths.values)\n",
    "    for path in paths:\n",
    "        try:\n",
    "            shutil.move(path, \"/dataset/cv/\" + str(i))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiKvQYyH8VRc"
   },
   "source": [
    "Transformation that is applied to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDGc4YZb8XSW"
   },
   "outputs": [],
   "source": [
    "# Define a sequence of transformation to be applied to an image\n",
    "transform_t = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),  # Resize the image to 224x224 pixels\n",
    "        transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "        transforms.Normalize(\n",
    "            mean=[0.5, 0.5, 0.5],  # Normalize the tensor by subtracting mean values\n",
    "            std=[\n",
    "                0.5,\n",
    "                0.5,\n",
    "                0.5,\n",
    "            ],  # Normalize the tensor by dividing by standard deviation values\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfomZ8mx8Zvp"
   },
   "source": [
    "Creating dataset and DataLoader objects of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIKhebum8dMl"
   },
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=\"/dataset/test/\", transform=transform_t\n",
    ")  # Create a testing dataset using the ImageFolder class from torchvision\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=False\n",
    ")\n",
    "\n",
    "cv_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=\"/dataset/cv/\", transform=transform_t\n",
    ")  # Create a cross-validation dataset using the ImageFolder class from torchvision\n",
    "cv_data_loader = DataLoader(\n",
    "    cv_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMdcCsIc8o4q"
   },
   "source": [
    "Install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4oOJw2Q87bn"
   },
   "outputs": [],
   "source": [
    "!pip install timm     # install timm module to import pretrained ViT models\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz9l4toXe2eN"
   },
   "source": [
    "Train and validate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqcWuTxme42O"
   },
   "outputs": [],
   "source": [
    "# funtion to train the model, takes in model,train_data_loader,optimizer and the loss function\n",
    "def train(model, trainloader, optimizer, criterion):\n",
    "    # set the model to train mode\n",
    "    model.train()\n",
    "    print(\"Training\")\n",
    "    # Initialize the variables to track loss and accuracy\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
    "        counter += 1\n",
    "        image, labels = data  # iterating over the dataloader\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()  # resetting all the gradients\n",
    "        outputs = model(image)  # forward pass\n",
    "\n",
    "        loss = criterion(outputs, labels)  # calculating the loss\n",
    "        train_running_loss += loss.item()  # keeping track of the loss\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)  # predicted class\n",
    "        train_running_correct += (\n",
    "            (preds == labels).sum().item()\n",
    "        )  # calculate the accuracy\n",
    "\n",
    "        loss.backward()  # backpropagation\n",
    "        optimizer.step()  # update the optimizer parameters\n",
    "\n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_acc = 100.0 * (train_running_correct / len(trainloader.dataset))\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, testloader, criterion):\n",
    "    model.eval()  # model is set to eval state so that no parameters are updated\n",
    "    print(\"Validation\")\n",
    "    valid_running_loss = 0.0  # initialize to store the loss\n",
    "    valid_running_correct = 0  # initialize to store the accuracy\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n",
    "            count += 1\n",
    "            image, labels = data\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(image)  # forward pass\n",
    "\n",
    "            loss = criterion(outputs, labels)  # calculate the loss\n",
    "            valid_running_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)  # calculate the accuracy\n",
    "            valid_running_correct += (preds == labels).sum().item()\n",
    "\n",
    "    epoch_loss = valid_running_loss / count  # loss and accuracy for the complete epoch\n",
    "    epoch_acc = 100.0 * (valid_running_correct / len(testloader.dataset))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f71u0ivA8-KD"
   },
   "source": [
    "Setting GPU/CPU for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rp791GDS9A16",
    "outputId": "9c9ae8ba-dc0e-4ff0-a15d-0e444cda0f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available and set the device accordingly\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Training on GPU\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPmjB2ef9C3H"
   },
   "source": [
    "Loading models so that we have the same architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "raCY4jGF9FG8"
   },
   "outputs": [],
   "source": [
    "model_valid = timm.create_model(\n",
    "    \"vit_base_patch16_224.augreg2_in21k_ft_in1k\", pretrained=False, num_classes=16\n",
    ").to(\n",
    "    device\n",
    ")  # loads the pretrained ViT data that is trained on ImageNet-21k and fine tuned on ImageNet-1k\n",
    "\n",
    "summary(model_valid, (3, 224, 224))  # to print the architecture of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEoxXNbJ-zjv"
   },
   "source": [
    "Loading the weights from the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STw9L-5S-_N6",
    "outputId": "8d6b412b-52e7-4a5e-f861-9cd8d598f22d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_point = torch.load(\n",
    "    \"/content/drive/MyDrive/model_DOC_VIT_6.pth\"\n",
    ")  # path to where the pretrained model is stored\n",
    "\n",
    "model_valid.load_state_dict(\n",
    "    check_point[\"model_state_dict\"]\n",
    ")  # load the weights to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5k_Esrq_bmU"
   },
   "source": [
    "Function to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdXoSCGr_30q"
   },
   "outputs": [],
   "source": [
    "import joblib  # package to dump files\n",
    "import numpy\n",
    "\n",
    "\n",
    "def feature_extraction(model, testloader, file_name):\n",
    "    model.eval()  # model is set to eval state so that no parameters are updated\n",
    "    print(\"Feature extraction\")\n",
    "    valid_running_loss = 0.0  # initialize the values to calculate loss\n",
    "    valid_running_correct = 0  # initialize the values to calculate accuracy\n",
    "    counter = 0\n",
    "    total_features = []  # list to store features\n",
    "    total_labels = []  # list to store the labels\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n",
    "            counter += 1\n",
    "            try:\n",
    "                image, labels = data\n",
    "                image = image.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model.forward_features(image)  # used to extract the features\n",
    "                output = (\n",
    "                    outputs[:, 0].cpu().numpy()\n",
    "                )  # transfer the data from cuda to cpu before dumping it using joblib\n",
    "                total_features.append(output)  # store all the features in this list\n",
    "                total_labels.append(labels)  # store all the labels in this list\n",
    "            except Exception as e:  # to catch exception\n",
    "                print(e)\n",
    "    joblib.dump(\n",
    "        total_features, file_name\n",
    "    )  # dump all the extracted features into a list\n",
    "    return total_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0VCsS7RZDr4"
   },
   "source": [
    "Extracting features for Test and cross-validation data and storing them in test_feat.joblib and cv_feat.joblib file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JHGqIWuZH6H",
    "outputId": "b2c2df98-4bd4-47c5-fbca-183d1a52b08d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [07:36<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [07:42<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "test_labels = feature_extraction(\n",
    "    model_valid, test_data_loader, \"test_feat\"\n",
    ")  # extracts the features of test data and returns the labels\n",
    "valid_labels = feature_extraction(\n",
    "    model_valid, cv_data_loader, \"cv_feat\"\n",
    ")  # extracts the features of cv data and returns the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tgB8dtdZP1m"
   },
   "source": [
    "concatenating the features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDURIo_ZZY7B",
    "outputId": "253768fa-887b-42d9-ac59-caf3145744ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39996, 768)\n",
      "(39995, 768)\n",
      "(39995,)\n",
      "(39996,)\n"
     ]
    }
   ],
   "source": [
    "features_test = joblib.load(\n",
    "    \"test_feat\"\n",
    ")  # load the features that was dumped in the test_feat.joblib\n",
    "features_numpy_test = numpy.concatenate(\n",
    "    features_test, axis=0\n",
    ")  # concatenate the features and convert them to numpy array\n",
    "print(features_numpy_test.shape)\n",
    "features_valid = joblib.load(\n",
    "    \"cv_feat\"\n",
    ")  # load the features that was dumped in the cv_feat.joblib\n",
    "features_numpy_valid = numpy.concatenate(\n",
    "    features_valid, axis=0\n",
    ")  # concatenate the features and convert them to numpy array\n",
    "print(features_numpy_valid.shape)\n",
    "\n",
    "labels_test = np.zeros((0))  # initialize a numpy array to store labels\n",
    "labels_valid = np.zeros((0))  # initialize a numpy array to store labels\n",
    "\n",
    "for l in test_labels:\n",
    "    labels_test = np.concatenate(\n",
    "        (labels_test, l.cpu()), axis=0\n",
    "    )  # concatenate the test labels\n",
    "for l in valid_labels:\n",
    "    labels_valid = np.concatenate(\n",
    "        (labels_valid, l.cpu()), axis=0\n",
    "    )  # concatenate the cv labels\n",
    "\n",
    "# test_labels_numpy = numpy.concatenate(test_labels,axis=0)\n",
    "print(labels_valid.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDO4MIXbZa-x"
   },
   "source": [
    "**Meta-Classifiers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMhpnjoRZuiP"
   },
   "source": [
    "SVM - Linear Classifier - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkPaxQlEZkqv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train = features_numpy_valid  # the cv features that are used to train the classifier\n",
    "Y_train = labels_valid  # cv labels used to train the classifier\n",
    "SVC = OneVsRestClassifier(SVC()).fit(X_train, Y_train)  # SVM classifier\n",
    "X_test = features_numpy_test  #  test features used for evaluation\n",
    "\n",
    "\n",
    "def evaluate(classifier, test_data, true_labels):  # function to evaluate the classifier\n",
    "    # Predict on the test set\n",
    "    y_pred = classifier.predict(test_data)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(true_labels, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "acc_SVC = evaluate(SVC, X_test, labels_test)  # accuracy from SVM\n",
    "print(\"SVM accuracy:{}\".format(acc_SVC * 100), \"%\")\n",
    "\n",
    "LC = OneVsRestClassifier(LogisticRegression()).fit(X_train, Y_train)\n",
    "acc_LC = evaluate(LC, X_test, labels_test)  # accuracy from LC\n",
    "print(\"LC accuracy:{}\".format(acc_LC * 100), \"%\")\n",
    "\n",
    "KNN = OneVsRestClassifier(KNeighborsClassifier()).fit(X_train, Y_train)\n",
    "acc_KNN = evaluate(KNN, X_test, labels_test)  # accuracy from KNN\n",
    "print(\"KNN accuracy:{}\".format(acc_KNN * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw8vbQerZyua"
   },
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Fdtm9bLZzz9"
   },
   "outputs": [],
   "source": [
    "# MLP for classifier of three hidden layers of size 512,256 and num_classes\n",
    "class mlp(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(mlp, self).__init__()\n",
    "        self.ln1 = nn.Linear(768, 512)\n",
    "        self.ln2 = nn.Linear(512, 256)\n",
    "        self.ln4 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.ln1(x))\n",
    "        x = torch.relu(self.ln2(x))\n",
    "        x = self.ln4(x)\n",
    "        sm = nn.Softmax(dim=1)\n",
    "        x = sm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5q7vWyUZ3A0"
   },
   "source": [
    "Dataloader for MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMTQlei8Z7Pm"
   },
   "outputs": [],
   "source": [
    "num_classes = 16\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "mlp_model = mlp(num_classes).to(device)  # initialize the mlp model\n",
    "valid_mlp_data = torch.Tensor(\n",
    "    features_numpy_valid\n",
    ")  # convert numpy data to torch tensor\n",
    "valid_mlp_lab = torch.Tensor(labels_valid).type(\n",
    "    torch.LongTensor\n",
    ")  # convert float type to long for weight updation on cuda\n",
    "valid_mlp_dataset = TensorDataset(\n",
    "    valid_mlp_data, valid_mlp_lab\n",
    ")  # load the torch dataset for cv data\n",
    "valid_mlp_dataloader = DataLoader(\n",
    "    valid_mlp_dataset, batch_size=32\n",
    ")  # load the torch dataloader for cv data\n",
    "\n",
    "test_mlp_data = torch.Tensor(features_numpy_test)  # convert numpy data to torch tensor\n",
    "test_mlp_lab = torch.Tensor(labels_test).type(\n",
    "    torch.LongTensor\n",
    ")  # convert float type to long for weight updation on cuda\n",
    "test_mlp_dataset = TensorDataset(\n",
    "    test_mlp_data, test_mlp_lab\n",
    ")  # load the torch dataset for test data\n",
    "test_mlp_dataloader = DataLoader(\n",
    "    test_mlp_dataset, batch_size=32\n",
    ")  # load the torch dataloader for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gsBC9ZpZ-GT"
   },
   "source": [
    "MLP training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nriXKN3aaALL"
   },
   "outputs": [],
   "source": [
    "mlp_optimizer = SGD(mlp_model.parameters(), lr=0.1)  # optimizer for MLP training\n",
    "mlp_loss = nn.CrossEntropyLoss()  # loss function\n",
    "train_loss = []  # list to store the cv loss during training\n",
    "train_acc = []  # list to store the cv accuracy\n",
    "valid_loss = []  # list to store the test loss\n",
    "valid_acc = []  # list to store the test accuracy\n",
    "for i in range(30):\n",
    "    train_epoch_loss, train_epoch_acc = train(\n",
    "        mlp_model, valid_mlp_dataloader, mlp_optimizer, mlp_loss\n",
    "    )  # train the mlp\n",
    "    valid_epoch_loss, valid_epoch_acc = validate(\n",
    "        mlp_model, test_mlp_dataloader, mlp_loss\n",
    "    )  # validate on the test dataset\n",
    "\n",
    "    # Append loss and accuracy values to lists\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    valid_loss.append(valid_epoch_loss)\n",
    "    train_acc.append(train_epoch_acc)\n",
    "    valid_acc.append(valid_epoch_acc)\n",
    "\n",
    "    # Print training and validation metrics\n",
    "    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n",
    "    print(\n",
    "        f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\"\n",
    "    )\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28tWlbWDaEB1"
   },
   "source": [
    "Evaluation Metric - Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UbTke2JaHsy"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    classifier, test_data, true_labels\n",
    "):  # function to evaluate and return the ground truth and predicted class\n",
    "    # Predict on the test set\n",
    "    y_pred = classifier.predict(test_data)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(true_labels, y_pred)\n",
    "    return accuracy, true_labels, y_pred\n",
    "\n",
    "\n",
    "_, gt_test, pred_test = evaluate(SVC, X_test, labels_test)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "confusion = confusion_matrix(gt_test.ravel(), pred_test.ravel())\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
